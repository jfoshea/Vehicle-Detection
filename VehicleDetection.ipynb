{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vehicle Detection** \n",
    "## Overview \n",
    "Develop a pipeline to identify the lane boundaries from a front-facing camera on a car. Extensive use of OpenCV, matplotlib, numpy will be used.\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "- Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "- Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "- Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "- Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "- Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "- Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDC Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction parameters\n",
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "spatial_size = (32, 32)\n",
    "hist_bins = 32\n",
    "orient = 11\n",
    "pix_per_cell = 16\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "def add_heat( heatmap, bbox_list ):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold( heatmap, threshold ):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[ heatmap <= threshold ] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes( img, labels ):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range( 1, labels[1]+1 ):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = ( labels[0] == car_number ).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array( nonzero[0] )\n",
    "        nonzerox = np.array( nonzero[1] )\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ( ( np.min( nonzerox ), np.min( nonzeroy ) ), ( np.max( nonzerox ), np.max( nonzeroy ) ) )\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle( img, bbox[0], bbox[1], (0,0,255), 6 )\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def draw_boxes( img, bboxes, color=( 0, 0, 255 ), thick = 6 ):\n",
    "    \"\"\" Function to Draw boxes around identified cars \"\"\"\n",
    "    img_copy = np.copy( img )\n",
    "    # Iterate over all discovered bounding boxes\n",
    "    for box in bboxes:\n",
    "        cv2.rectangle( img_copy, box[0], box[1], color, thick )\n",
    "    return img_copy\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "#def get_hog_features( img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True ):\n",
    "#    # Call with two outputs if vis==True\n",
    "#    if vis == True:\n",
    "#        features, hog_image = hog(img, \n",
    "#                                  orientations = orient, \n",
    "#                                  pixels_per_cell =( pix_per_cell, pix_per_cell ),\n",
    "#                                  block_norm = 'L2-Hys',\n",
    "#                                  cells_per_block = ( cell_per_block, cell_per_block ), \n",
    "#                                  transform_sqrt = True, \n",
    "#                                  visualise = vis, \n",
    "#                                  feature_vector = feature_vec )\n",
    "#        return features, hog_image\n",
    "#    # Otherwise call with one output\n",
    "#    else:      \n",
    "#        features = hog(img, \n",
    "#                       orientations = orient, \n",
    "#                       pixels_per_cell = ( pix_per_cell, pix_per_cell ),\n",
    "#                       cells_per_block = ( cell_per_block, cell_per_block ), \n",
    "#                       block_norm = 'L2-Hys',\n",
    "#                       transform_sqrt = True, \n",
    "#                       visualise = vis, \n",
    "#                       feature_vector = feature_vec )\n",
    "#        return features\n",
    "    \n",
    "def get_hog_features(img, color_space='YUV'):\n",
    "    # Call with two outputs if vis==True\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'Lab':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    hog = cv2.HOGDescriptor((64,64), (16,16), (8,8), (8,8), 9)\n",
    "\n",
    "    return np.ravel(hog.compute(feature_image))\n",
    "hog = cv2.HOGDescriptor((64,64), (8,8), (8,8), (8,8), 9)\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "hog.compute(image).shape\n",
    "\n",
    "def extract_features( imgs, color_space='RGB', orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=0 ):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        img = mpimg.imread( file )\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_img = cv2.cvtColor( img, cv2.COLOR_RGB2HSV )\n",
    "            elif color_space == 'LUV':\n",
    "                feature_img = cv2.cvtColor( img, cv2.COLOR_RGB2LUV )\n",
    "            elif color_space == 'HLS':\n",
    "                feature_img = cv2.cvtColor( img, cv2.COLOR_RGB2HLS )\n",
    "            elif color_space == 'YUV':\n",
    "                feature_img = cv2.cvtColor( img, cv2.COLOR_RGB2YUV )\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_img = cv2.cvtColor( img, cv2.COLOR_RGB2YCrCb )\n",
    "        else: feature_img = np.copy( img )      \n",
    "\n",
    "        ## Call get_hog_features() with vis=False, feature_vec=True\n",
    "        #if hog_channel == 'ALL':\n",
    "        #    hog_features = []\n",
    "        #    for channel in range( feature_img.shape[2] ):\n",
    "        #        hog_features.append(get_hog_features( feature_img[:,:,channel], \n",
    "        #                            orient, \n",
    "        #                            pix_per_cell, \n",
    "        #                            cell_per_block, \n",
    "        #                            vis = False, \n",
    "        #                            feature_vec = True ) )\n",
    "        #    hog_features = np.ravel( hog_features )        \n",
    "        #else:\n",
    "        #    hog_features = get_hog_features(feature_img[:,:,hog_channel], orient, \n",
    "        #                                    pix_per_cell, \n",
    "        #                                    cell_per_block, \n",
    "        #                                    vis = False, \n",
    "        #                                    feature_vec = True )\n",
    "        #features.append( hog_features )\n",
    "        hog_features = np.ravel(hog.compute(feature_img))\n",
    "        features.append(hog_features)\n",
    "    return features\n",
    "    #return np.concatenate( features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all car images\n",
    "car_images = glob.glob('vehicles/*/*.png')\n",
    "print( \"Number of car images = {}\".format( len( car_images ) ) )\n",
    "\n",
    "# Get all non-car images\n",
    "non_car_images = glob.glob('non-vehicles/*/*.png')\n",
    "print( \"Number of non-car images = {}\".format( len( non_car_images ) ) )\n",
    "\n",
    "# Read random car image\n",
    "car_path = car_images[ np.random.randint( 0, len( car_images ) ) ]\n",
    "_, car_filename = os.path.split( car_path )\n",
    "car_img = mpimg.imread( car_path )\n",
    "\n",
    "# Read random non-car image\n",
    "non_car_path = non_car_images[ np.random.randint( 0, len( non_car_images ) ) ]\n",
    "_, non_car_filename = os.path.split( non_car_path )\n",
    "non_car_img = mpimg.imread( non_car_path )\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots( 1, 2, figsize=( 25, 10 ) )\n",
    "f.subplots_adjust( hspace = .2, wspace=.05 )\n",
    "f.tight_layout()\n",
    "ax1.imshow( car_img )\n",
    "ax1.set_title( 'Car-' + car_filename, fontsize=40 )\n",
    "ax2.imshow( non_car_img )\n",
    "ax2.set_title( 'Non-Car-' + non_car_filename, fontsize=40 );       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all car images\n",
    "test_images = glob.glob( 'test_images/test*.jpg' )\n",
    "\n",
    "print( \"Number of test images = {}\".format( len( test_images ) ) )\n",
    "\n",
    "# Read a random test image\n",
    "path = test_images[ np.random.randint( 0, len( test_images ) ) ]\n",
    "_, filename = os.path.split( path )\n",
    "img = mpimg.imread( path )\n",
    "\n",
    "plt.imshow( img )\n",
    "plt.title( filename, fontsize=40 );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize bounding boxes on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(test_images):\n",
    "    _, filename = os.path.split( path )\n",
    "    print(\"filename = \",filename)\n",
    "    \n",
    "    if filename == 'test1.jpg':\n",
    "        bboxes = [ ( ( 810,400 ),( 950,500 ) ), ( ( 1045,400 ), ( 1270,505 ) ) ]\n",
    "    elif filename == 'test2.jpg':\n",
    "        bboxes = [ ( ( 0,0 ),( 0,0 ) ), ( ( 0,0 ), ( 0,0 ) ) ]\n",
    "    elif filename == 'test3.jpg':\n",
    "        bboxes = [ ( ( 865,410 ),( 970,470 ) ), ( ( 0,0 ), ( 0,0 ) ) ]\n",
    "    elif filename == 'test4.jpg':\n",
    "        bboxes = [ ( ( 810,400 ),( 950,495 ) ), ( ( 1030,400 ), ( 1260,505 ) ) ]\n",
    "    elif filename == 'test5.jpg':\n",
    "        bboxes = [ ( ( 810,400 ),( 950,495 ) ), ( ( 1075,400 ), ( 1280,505 ) ) ]\n",
    "    elif filename == 'test6.jpg':\n",
    "        bboxes = [ ( ( 810,400 ),( 950,495 ) ), ( ( 1005,400 ), ( 1205,505 ) ) ]\n",
    "    else:\n",
    "        print( \"unknown filename\" )\n",
    "    img = mpimg.imread( path ) \n",
    "    _, filename = os.path.split( path )        \n",
    "    box_img = draw_boxes( img, bboxes = bboxes )\n",
    "    f, (ax1, ax2) = plt.subplots( 1, 2, figsize=( 25, 10 ) )\n",
    "    f.subplots_adjust( hspace = .2, wspace=.05 )\n",
    "    f.tight_layout()\n",
    "    ax1.imshow( img )\n",
    "    ax1.set_title( filename, fontsize=40 )\n",
    "    ax2.imshow( box_img )\n",
    "    ax2.set_title( 'Box-'+filename, fontsize=40 );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Histogram of Gradient (HOG) and Visualize for Random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Select a random car image and display its Histogram Of Gradients \n",
    "#\n",
    "car_path = car_images[ np.random.randint( 0, len( car_images ) ) ]\n",
    "_, car_filename = os.path.split( car_path )\n",
    "car_img = mpimg.imread( car_path )\n",
    "#_, hog_car = get_hog_features( car_img[:,:,2], 9, 8, 8, vis=True, feature_vec=True )\n",
    "#_, hog_car = get_hog_features( car_img[:,:,2], 11, 16, 2, vis=True, feature_vec=True )\n",
    "hog_car = get_hog_features( car_img, color_space=color_space )\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots( 1, 2, figsize=( 25, 10 ) )\n",
    "f.subplots_adjust( hspace = .2, wspace=.05 )\n",
    "f.tight_layout()\n",
    "ax1.imshow( car_img )\n",
    "ax1.set_title( 'Car-' + car_filename, fontsize=40 )\n",
    "ax2.imshow( hog_car, cmap='gray' )\n",
    "ax2.set_title( 'Hog-Car-' + car_filename, fontsize=40 );    \n",
    "\n",
    "#\n",
    "# Select a random non-car image and display its Histogram Of Gradients\n",
    "#\n",
    "\n",
    "non_car_path = non_car_images[ np.random.randint( 0, len( non_car_images ) ) ]\n",
    "_, non_car_filename = os.path.split( non_car_path )\n",
    "non_car_img = mpimg.imread( non_car_path )\n",
    "#_, non_car_hog = get_hog_features( non_car_img[:,:,2], 9, 8, 8, vis=True, feature_vec=True )\n",
    "#_, hog_car = get_hog_features( car_img[:,:,2], 11, 16, 2, vis=True, feature_vec=True )\n",
    "hog_non_car = get_hog_features( non_car_img, color_space=color_space )\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots( 1, 2, figsize=( 25, 10 ) )\n",
    "f.subplots_adjust( hspace = .2, wspace=.05 )\n",
    "f.tight_layout()\n",
    "ax1.imshow( non_car_img )\n",
    "ax1.set_title( 'Non-Car-' + non_car_filename, fontsize=40 )\n",
    "ax2.imshow( hog_non_car, cmap='gray' )\n",
    "ax2.set_title( 'Hog-Non-Car-' + non_car_filename, fontsize=40 );    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all Features from both Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_features = extract_features(car_images,\n",
    "                                color_space = color_space, \n",
    "                                orient = orient, \n",
    "                                pix_per_cell = pix_per_cell, \n",
    "                                cell_per_block = cell_per_block, \n",
    "                                hog_channel = hog_channel )\n",
    "\n",
    "non_car_features = extract_features(non_car_images, \n",
    "                                    color_space = color_space, \n",
    "                                    orient = orient, \n",
    "                                    pix_per_cell = pix_per_cell, \n",
    "                                    cell_per_block = cell_per_block, \n",
    "                                    hog_channel = hog_channel )\n",
    "\n",
    "print( 'Number of car_features = {}'.format( len( car_features[0] ) ) )\n",
    "\n",
    "print( 'Number of non_car_features = {}'.format( len( non_car_features[0] ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack( ( car_features, non_car_features ) ).astype( np.float64 )\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit( X )\n",
    "\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform( X )\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack( ( np.ones( len( car_features ) ), np.zeros( len( non_car_features ) ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the normalized data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Display a random car image along with the un-normalized, and normalized image data\n",
    "#\n",
    "car_path = car_images[ np.random.randint( 0, len( car_images ) ) ]\n",
    "_, car_filename = os.path.split( car_path )\n",
    "car_img = mpimg.imread( car_path )\n",
    "\n",
    "f, (ax1, ax2,ax3) = plt.subplots( 1, 3, figsize=( 25, 10 ) )\n",
    "f.subplots_adjust( hspace = .2, wspace=.05 )\n",
    "f.tight_layout()\n",
    "ax1.imshow( car_img )\n",
    "ax1.set_title( 'Car-' + car_filename, fontsize=40 )\n",
    "ax2.plot( X[ 0 ])\n",
    "ax2.set_title('Un-Normalized-' + car_filename, fontsize=30 )\n",
    "ax3.plot( scaled_X[0] )\n",
    "ax3.set_title( 'Normalized-' + car_filename, fontsize=30 );    \n",
    "\n",
    "#\n",
    "# Display a random non_car image along with the un-normalized, and normalized image data\n",
    "#\n",
    "non_car_path = non_car_images[ np.random.randint( 0, len( non_car_images ) ) ]\n",
    "_, non_car_filename = os.path.split( non_car_path )\n",
    "non_car_img = mpimg.imread( non_car_path )\n",
    "\n",
    "f, (ax1, ax2,ax3) = plt.subplots( 1, 3, figsize=( 25, 10 ) )\n",
    "f.subplots_adjust( hspace = .2, wspace=.05 )\n",
    "f.tight_layout()\n",
    "ax1.imshow( non_car_img )\n",
    "ax1.set_title( 'Non-Car-' + non_car_filename, fontsize=30 )\n",
    "ax2.plot( X[ 0 ])\n",
    "ax2.set_title('Un-Normalized-' + non_car_filename, fontsize=30 )\n",
    "ax3.plot( scaled_X[0] )\n",
    "ax3.set_title( 'Normalized-' + non_car_filename, fontsize=30 );    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up the data sets into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 80% for training 20% for test\n",
    "random_state = np.random.randint( 0, len( car_features ) )\n",
    "X_train, X_test, y_train, y_test = train_test_split( scaled_X, y, test_size = 0.2, random_state=random_state )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "\n",
    "svc.fit( X_train, y_train )\n",
    "\n",
    "# Check the score of the SVC\n",
    "print( 'LinearSVC Test Accuracy = {:.2%}'.format( svc.score( X_test, y_test ) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the mode\n",
    "joblib.dump( ( svc, X_scaler ), 'model.pkl')\n",
    "\n",
    "# reload\n",
    "svc, X_scaler = joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Window Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.75, 0.75)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) \n",
    "    ny_windows = np.int(yspan/ny_pix_per_step)\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = (xs+1)*nx_pix_per_step + x_start_stop[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = (ys+1)*ny_pix_per_step + y_start_stop[0]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
